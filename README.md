# book2notion

Convert technical books (PDF + HTML) into structured, LLM-summarized Markdown and JSON notes — optimized for study, reference, and technical interview prep.

## Overview

The pipeline has two stages:

```
content.pdf + content.html
        │
        ▼
  convert_book.py          →  content.json  +  images/
        │
        ▼
  summarize_book.py         →  outputs/<chapter>.json  +  outputs/<chapter>.md
```

1. **`convert_book.py`** — Extracts the TOC from the PDF and uses it to parse the HTML into a structured `content.json`, saving embedded images to `images/`.
2. **`summarize_book.py`** — Feeds each section from `content.json` to an LLM (OpenAI-compatible API) and writes per-chapter `.json` and `.md` notes.

## Directory Structure

```
books/
  <Book Name>/
    content.pdf          ← source PDF (for TOC extraction)
    content.html         ← source HTML (for content parsing)
    content.json         ← generated by convert_book.py
    images/              ← extracted images
    outputs/
      1. Chapter.json    ← structured LLM output
      1. Chapter.md      ← rendered Markdown notes
prompts/
  summarize.md           ← system prompt for the LLM
```

## Setup

**1. Install dependencies**

```bash
pip install openai tqdm python-dotenv beautifulsoup4 PyPDF2
```

**2. Configure environment**

Copy `.env.example` to `.env` and fill in your values:

```dotenv
LLM_BASE_URL=https://api.openai.com/v1   # any OpenAI-compatible endpoint
LLM_API_KEY=sk-...
LLM_ID=gpt-4o                            # model identifier
```

## Usage

### Step 1 — Convert book to JSON

Place `content.pdf` and `content.html` inside `books/<Book Name>/`, then run:

```bash
python convert_book.py "books/DDIA"
```

This produces `books/DDIA/content.json` and saves images to `books/DDIA/images/`.

Supported TOC formats:
- **named** — `Chapter N. Title` chapters with plain-text sections (O'Reilly / DDIA style)
- **numbered** — `Chapter N Title` or `N. Title` chapters with `N.N` numbered sections (textbook style)

### Step 2 — Summarize with LLM

```bash
# All chapters
python summarize_book.py --book "DDIA"

# Specific chapters
python summarize_book.py --book "DDIA" --chapter 1 --chapter 3
```

Already-processed chapters are skipped automatically (resume-safe).

## Output Format

Each chapter produces two files in `outputs/`:

| File | Description |
|------|-------------|
| `<N>. <Chapter>.json` | Raw structured LLM output (sections array) |
| `<N>. <Chapter>.md` | Rendered Markdown ready for import into Notion or any notes app |

### JSON schema per section

```json
{
  "name": "Section Title",
  "summary": "One-sentence summary.",
  "retained": [{ "name": "concept", "reason": "why kept" }],
  "omitted":  [{ "name": "concept", "reason": "why dropped" }],
  "subsections": [
    {
      "name": "Subheading",
      "content": "Markdown content",
      "figures": [
        { "caption": "Alt text of image", "id": 1 }
      ]
    }
  ],
  "code": { "content": "...", "lang": "go" },
  "interview": [
    { "question": "...", "level": "junior|mid-level|senior", "answer": "..." }
  ],
  "more": [{ "name": "Topic", "content": "Real-world context" }]
}
```

### Markdown structure per section

```
# Section Title
<one-sentence summary>

## Subheading
<bullet points / paragraphs>
![figure caption](images/image_0001.jpeg)

```go
// code block (if applicable)
```

__*Interview:*__
> **Question:** ... (level: senior)
> **Answer:** ...

__*More:*__
### Real-World Topic
<real-world context>

---
Editorial Logic:
Retained: ...
Omitted:  ...
```

## Configuration

| Environment variable | Description |
|----------------------|-------------|
| `LLM_BASE_URL` | OpenAI-compatible API base URL |
| `LLM_API_KEY` | API key |
| `LLM_ID` | Model identifier (e.g. `gpt-4o`, `claude-3-opus`) |

Advanced constants in `summarize_book.py`:

| Constant | Default | Description |
|----------|---------|-------------|
| `TIMEOUT_SECONDS` | `160` | Per-LLM-call timeout |
| `MAX_RETRIES` | `3` | Retry attempts on failure |
| `MAX_WORKERS` | `8` | Concurrent threads per chapter |
